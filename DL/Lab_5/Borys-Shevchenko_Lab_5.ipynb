{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PyTorch exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensors\n",
    "\n",
    "1. Make a tensor of size (2, 17)\n",
    "2. Make a torch.FloatTensor of size (3, 1)\n",
    "3. Make a torch.LongTensor of size (5, 2, 1)\n",
    "  - fill the entire tensor with 7s\n",
    "4. Make a torch.ByteTensor of size (5,)\n",
    "  - fill the middle 3 indices with ones such that it records [0, 1, 1, 1, 0]\n",
    "5. Perform a matrix multiplication of two tensors of size (2, 4) and (4, 2). Then do it in-place.\n",
    "6. Do element-wise multiplication of two randomly filled $(n_1,n_2,n_3)$ tensors. Then store the result in an Numpy array.\n",
    "\n",
    "### Forward-prop/backward-prop\n",
    "1. Create a Tensor that `requires_grad` of size (5, 5).\n",
    "2. Sum the values in the Tensor.\n",
    "3. Multiply the tensor by 2 and assign the result to a new python variable (i.e. `x = result`)\n",
    "4. Sum the variable's elements and assign to a new python variable\n",
    "5. Print the gradients of all the variables\n",
    "6. Now perform a backward pass on the last variable (NOTE: for each new python variable that you define, call `.retain_grad()`)\n",
    "7. Print all gradients again\n",
    "\n",
    "### Deep-forward NNs\n",
    "1. Use dl_lab2. In Exercise 12 there, you had to build an $L$-layer neural network with the following structure: *[LINEAR -> RELU]$\\times$(L-1) -> LINEAR -> SIGMOID*. Reimplement the manual code in PyTorch.\n",
    "2. Compare test accuracy using different optimizers: SGD, Adam, Momentum."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementing a deep convolutional neural network using PyTorch\n",
    "\n",
    "### The multilayer CNN architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading and preprocessing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torchvision \n",
    "from torchvision import transforms \n",
    "image_path = './'\n",
    "transform = transforms.Compose([transforms.ToTensor()])\n",
    "\n",
    "mnist_dataset = torchvision.datasets.MNIST(root=image_path, \n",
    "                                           train=True, \n",
    "                                           transform=transform, \n",
    "                                           download=True)\n",
    "\n",
    "from torch.utils.data import Subset\n",
    "mnist_valid_dataset = Subset(mnist_dataset, torch.arange(10000)) \n",
    "mnist_train_dataset = Subset(mnist_dataset, torch.arange(10000, len(mnist_dataset)))\n",
    "mnist_test_dataset = torchvision.datasets.MNIST(root=image_path, \n",
    "                                           train=False, \n",
    "                                           transform=transform, \n",
    "                                           download=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "batch_size = 64\n",
    "torch.manual_seed(1)\n",
    "train_dl = DataLoader(mnist_train_dataset, batch_size, shuffle=True)\n",
    "valid_dl = DataLoader(mnist_valid_dataset, batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementing a CNN using the torch.nn module\n",
    "\n",
    "#### Configuring CNN layers in PyTorch\n",
    "\n",
    " * **Conv2d:** `torch.nn.Conv2d`\n",
    "   * `out_channels`\n",
    "   * `kernel_size`\n",
    "   * `stride`\n",
    "   * `padding`\n",
    "   \n",
    "   \n",
    " * **MaxPool2d:** `torch.nn.MaxPool2d`\n",
    "   * `kernel_size`\n",
    "   * `stride`\n",
    "   * `padding`\n",
    "   \n",
    "   \n",
    " * **Dropout** `torch.nn.Dropout`\n",
    "   * `p`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constructing a CNN in PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 64, 7, 7])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "model = nn.Sequential()\n",
    "model.add_module('conv1', nn.Conv2d(in_channels=1, out_channels=32, kernel_size=5, padding=2))\n",
    "model.add_module('relu1', nn.ReLU())        \n",
    "model.add_module('pool1', nn.MaxPool2d(kernel_size=2))   \n",
    "model.add_module('conv2', nn.Conv2d(in_channels=32, out_channels=64, kernel_size=5, padding=2))\n",
    "model.add_module('relu2', nn.ReLU())        \n",
    "model.add_module('pool2', nn.MaxPool2d(kernel_size=2))      \n",
    "\n",
    "x = torch.ones((4, 1, 28, 28))\n",
    "model(x).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 3136])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.add_module('flatten', nn.Flatten()) \n",
    "\n",
    "x = torch.ones((4, 1, 28, 28))\n",
    "model(x).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add_module('fc1', nn.Linear(3136, 1024)) \n",
    "model.add_module('relu3', nn.ReLU()) \n",
    "model.add_module('dropout', nn.Dropout(p=0.5)) \n",
    "\n",
    "model.add_module('fc2', nn.Linear(1024, 10)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"mps\")\n",
    "#device = torch.device(\"cpu\")\n",
    "\n",
    "model = model.to(device) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 accuracy: 0.9482 val_accuracy: 0.9816\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[26], line 45\u001b[0m\n\u001b[1;32m     43\u001b[0m torch\u001b[38;5;241m.\u001b[39mmanual_seed(\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     44\u001b[0m num_epochs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m20\u001b[39m\n\u001b[0;32m---> 45\u001b[0m hist \u001b[38;5;241m=\u001b[39m train(model, num_epochs, train_dl, valid_dl)\n",
      "Cell \u001b[0;32mIn[26], line 19\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, num_epochs, train_dl, valid_dl)\u001b[0m\n\u001b[1;32m     17\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     18\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m---> 19\u001b[0m loss_hist_train[epoch] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\u001b[38;5;241m*\u001b[39my_batch\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     20\u001b[0m is_correct \u001b[38;5;241m=\u001b[39m (torch\u001b[38;5;241m.\u001b[39margmax(pred, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m==\u001b[39m y_batch)\u001b[38;5;241m.\u001b[39mfloat()\n\u001b[1;32m     21\u001b[0m accuracy_hist_train[epoch] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m is_correct\u001b[38;5;241m.\u001b[39msum()\u001b[38;5;241m.\u001b[39mcpu()\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "def train(model, num_epochs, train_dl, valid_dl):\n",
    "    loss_hist_train = [0] * num_epochs\n",
    "    accuracy_hist_train = [0] * num_epochs\n",
    "    loss_hist_valid = [0] * num_epochs\n",
    "    accuracy_hist_valid = [0] * num_epochs\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        for x_batch, y_batch in train_dl:\n",
    "            x_batch = x_batch.to(device) \n",
    "            y_batch = y_batch.to(device) \n",
    "            pred = model(x_batch)\n",
    "            loss = loss_fn(pred, y_batch)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            loss_hist_train[epoch] += loss.item()*y_batch.size(0)\n",
    "            is_correct = (torch.argmax(pred, dim=1) == y_batch).float()\n",
    "            accuracy_hist_train[epoch] += is_correct.sum().cpu()\n",
    "\n",
    "        loss_hist_train[epoch] /= len(train_dl.dataset)\n",
    "        accuracy_hist_train[epoch] /= len(train_dl.dataset)\n",
    "        \n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            for x_batch, y_batch in valid_dl:\n",
    "                x_batch = x_batch.to(device) \n",
    "                y_batch = y_batch.to(device) \n",
    "                pred = model(x_batch)\n",
    "                loss = loss_fn(pred, y_batch)\n",
    "                loss_hist_valid[epoch] += loss.item()*y_batch.size(0) \n",
    "                is_correct = (torch.argmax(pred, dim=1) == y_batch).float() \n",
    "                accuracy_hist_valid[epoch] += is_correct.sum().cpu()\n",
    "\n",
    "        loss_hist_valid[epoch] /= len(valid_dl.dataset)\n",
    "        accuracy_hist_valid[epoch] /= len(valid_dl.dataset)\n",
    "        \n",
    "        print(f'Epoch {epoch+1} accuracy: {accuracy_hist_train[epoch]:.4f} val_accuracy: {accuracy_hist_valid[epoch]:.4f}')\n",
    "    return loss_hist_train, loss_hist_valid, accuracy_hist_train, accuracy_hist_valid\n",
    "\n",
    "torch.manual_seed(1)\n",
    "num_epochs = 20\n",
    "hist = train(model, num_epochs, train_dl, valid_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "x_arr = np.arange(len(hist[0])) + 1\n",
    "\n",
    "fig = plt.figure(figsize=(12, 4))\n",
    "ax = fig.add_subplot(1, 2, 1)\n",
    "ax.plot(x_arr, hist[0], '-o', label='Train loss')\n",
    "ax.plot(x_arr, hist[1], '--<', label='Validation loss')\n",
    "ax.set_xlabel('Epoch', size=15)\n",
    "ax.set_ylabel('Loss', size=15)\n",
    "ax.legend(fontsize=15)\n",
    "ax = fig.add_subplot(1, 2, 2)\n",
    "ax.plot(x_arr, hist[2], '-o', label='Train acc.')\n",
    "ax.plot(x_arr, hist[3], '--<', label='Validation acc.')\n",
    "ax.legend(fontsize=15)\n",
    "ax.set_xlabel('Epoch', size=15)\n",
    "ax.set_ylabel('Accuracy', size=15)\n",
    "\n",
    "#plt.savefig('figures/14_13.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.mps.synchronize()\n",
    "model_cpu = model.cpu()\n",
    "pred = model(mnist_test_dataset.data.unsqueeze(1) / 255.)\n",
    "is_correct = (torch.argmax(pred, dim=1) == mnist_test_dataset.targets).float()\n",
    "print(f'Test accuracy: {is_correct.mean():.4f}') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(12, 4))\n",
    "for i in range(12):\n",
    "    ax = fig.add_subplot(2, 6, i+1)\n",
    "    ax.set_xticks([]); ax.set_yticks([])\n",
    "    img = mnist_test_dataset[i][0][0, :, :]\n",
    "    pred = model(img.unsqueeze(0).unsqueeze(1))\n",
    "    y_pred = torch.argmax(pred)\n",
    "    ax.imshow(img, cmap='gray_r')\n",
    "    ax.text(0.9, 0.1, y_pred.item(), \n",
    "            size=15, color='blue',\n",
    "            horizontalalignment='center',\n",
    "            verticalalignment='center', \n",
    "            transform=ax.transAxes)\n",
    "    \n",
    "    \n",
    "#plt.savefig('figures/14_14.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'torch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m     os\u001b[38;5;241m.\u001b[39mmkdir(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodels\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      6\u001b[0m path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodels/mnist-cnn.ph\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m----> 7\u001b[0m torch\u001b[38;5;241m.\u001b[39msave(model, path)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'torch' is not defined"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "if not os.path.exists('models'):\n",
    "    os.mkdir('models')\n",
    "\n",
    "path = 'models/mnist-cnn.ph'\n",
    "torch.save(model, path)\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensors\n",
    "## 1. Make a tensor of size (2, 17)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.Tensor(2, 17)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Make a torch.FloatTensor of size (3, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.],\n",
       "        [0.],\n",
       "        [0.]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.FloatTensor(3, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Make a torch.LongTensor of size (5, 2, 1)  - fill the entire tensor with 7s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[7],\n",
       "         [7]],\n",
       "\n",
       "        [[7],\n",
       "         [7]],\n",
       "\n",
       "        [[7],\n",
       "         [7]],\n",
       "\n",
       "        [[7],\n",
       "         [7]],\n",
       "\n",
       "        [[7],\n",
       "         [7]]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.full((5, 2, 1), 7, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Make a torch.ByteTensor of size (5,) - fill the middle 3 indices with ones such that it records [0, 1, 1, 1, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 1, 1, 0], dtype=torch.uint8)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.ByteTensor(5,)\n",
    "x[1:-1] = 1\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Perform a matrix multiplication of two tensors of size (2, 4) and (4, 2). Then do it in-place."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0.],\n",
      "        [0., 0.]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0.],\n",
       "        [0., 0.]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(torch.mm(torch.Tensor(2, 4), torch.Tensor(4, 2)))\n",
    "\n",
    "torch.Tensor(2, 4).mm(torch.Tensor(4, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Do element-wise multiplication of two randomly filled $(n_1,n_2,n_3)$ tensors. Then store the result in an Numpy array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 0.28335887,  0.35737008,  1.0660723 , -0.35816902,\n",
       "         -0.4373236 ]],\n",
       "\n",
       "       [[-0.26933527, -0.17327414,  2.0608163 , -0.61397487,\n",
       "         -0.3014985 ]],\n",
       "\n",
       "       [[ 0.15328172, -0.5223642 ,  0.24036913,  1.5886065 ,\n",
       "         -0.3230379 ]],\n",
       "\n",
       "       [[ 0.12424187, -1.0215594 ,  0.12761118, -0.03351678,\n",
       "          0.36481565]],\n",
       "\n",
       "       [[ 0.95602643, -1.3625723 ,  0.70075905,  0.554543  ,\n",
       "         -0.22817194]],\n",
       "\n",
       "       [[-1.1015437 , -1.0414515 ,  0.48947513,  0.00321078,\n",
       "         -0.6435812 ]]], dtype=float32)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n1, n2, n3 = 6, 1, 5\n",
    "\n",
    "torch.mul(torch.randn(n1, n2, n3), torch.randn(n1, n2, n3)).numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Forward-prop/backward-prop\n",
    "## 1. Create a Tensor that `requires_grad` of size (5, 5).\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.9276,  1.1120,  0.6155,  0.1938, -2.5832],\n",
       "        [ 0.8539,  1.2466,  0.5057, -1.4782,  0.6147],\n",
       "        [ 0.7124, -1.7765,  0.3539,  1.1996, -0.3030],\n",
       "        [-1.7618,  0.6348, -0.7893, -1.6111, -1.8716],\n",
       "        [ 0.5431,  0.6607,  2.2952,  0.6749,  1.7133]], requires_grad=True)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor = torch.randn(5, 5, requires_grad=True)\n",
    "tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Sum the values in the Tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8278233408927917"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor.sum().item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Multiply the tensor by 2 and assign the result to a new python variable (i.e. `x = result`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.8552,  2.2239,  1.2311,  0.3876, -5.1664],\n",
       "        [ 1.7079,  2.4931,  1.0114, -2.9565,  1.2295],\n",
       "        [ 1.4247, -3.5530,  0.7077,  2.3992, -0.6060],\n",
       "        [-3.5237,  1.2697, -1.5785, -3.2222, -3.7432],\n",
       "        [ 1.0862,  1.3214,  4.5904,  1.3498,  3.4266]], grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = tensor * 2\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Sum the variable's elements and assign to a new python variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.6556466817855835"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = x.sum()\n",
    "y.item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Print the gradients of all the variables\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2., 2., 2., 2., 2.],\n",
       "        [2., 2., 2., 2., 2.],\n",
       "        [2., 2., 2., 2., 2.],\n",
       "        [2., 2., 2., 2., 2.],\n",
       "        [2., 2., 2., 2., 2.]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.backward()\n",
    "\n",
    "tensor.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Now perform a backward pass on the last variable (NOTE: for each new python variable that you define, call `.retain_grad()`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2., 2., 2., 2., 2.],\n",
       "        [2., 2., 2., 2., 2.],\n",
       "        [2., 2., 2., 2., 2.],\n",
       "        [2., 2., 2., 2., 2.],\n",
       "        [2., 2., 2., 2., 2.]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor = torch.randn(5, 5, requires_grad=True)\n",
    "tensor.retain_grad()\n",
    "\n",
    "output = tensor * 2\n",
    "output.retain_grad()  \n",
    "\n",
    "output.sum().backward()\n",
    "\n",
    "tensor.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Print all gradients again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[2., 2., 2., 2., 2.],\n",
      "        [2., 2., 2., 2., 2.],\n",
      "        [2., 2., 2., 2., 2.],\n",
      "        [2., 2., 2., 2., 2.],\n",
      "        [2., 2., 2., 2., 2.]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1.]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(tensor.grad)\n",
    "output.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep-forward NNs\n",
    "## 1. Use dl_lab2. In Exercise 12 there, you had to build an $L$-layer neural network with the following structure: *[LINEAR -> RELU]$\\times$(L-1) -> LINEAR -> SIGMOID*. Reimplement the manual code in PyTorch.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    train_dataset = h5py.File('datasets/train_catvnoncat.h5', \"r\")\n",
    "    train_set_x_orig = np.array(train_dataset[\"train_set_x\"][:]) # your train set features\n",
    "    train_set_y_orig = np.array(train_dataset[\"train_set_y\"][:]) # your train set labels\n",
    "\n",
    "    test_dataset = h5py.File('datasets/test_catvnoncat.h5', \"r\")\n",
    "    test_set_x_orig = np.array(test_dataset[\"test_set_x\"][:]) # your test set features\n",
    "    test_set_y_orig = np.array(test_dataset[\"test_set_y\"][:]) # your test set labels\n",
    "\n",
    "    classes = np.array(test_dataset[\"list_classes\"][:]) # the list of classes\n",
    "    \n",
    "    train_set_y_orig = train_set_y_orig.reshape((1, train_set_y_orig.shape[0]))\n",
    "    test_set_y_orig = test_set_y_orig.reshape((1, test_set_y_orig.shape[0]))\n",
    "    \n",
    "    return train_set_x_orig, train_set_y_orig, test_set_x_orig, test_set_y_orig, classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x_orig, train_y, test_x_orig, test_y, classes = load_data()\n",
    "\n",
    "\n",
    "train_x_flatten = train_x_orig.reshape(train_x_orig.shape[0], -1).T   # The \"-1\" makes reshape flatten the remaining dimensions\n",
    "test_x_flatten = test_x_orig.reshape(test_x_orig.shape[0], -1).T\n",
    "\n",
    "train_x = train_x_flatten/255.\n",
    "test_x = test_x_flatten/255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LLayerNN(nn.Module):\n",
    "    def __init__(self, layer_dims):\n",
    "        super(LLayerNN, self).__init__()\n",
    "        self.layer_dims = layer_dims\n",
    "        self.num_layers = len(layer_dims) - 1\n",
    "        self.layers = nn.ModuleList()\n",
    "\n",
    "        for l in range(1, self.num_layers):\n",
    "            self.layers.append(nn.Linear(layer_dims[l-1], layer_dims[l]))\n",
    "            self.layers.append(nn.ReLU())\n",
    "\n",
    "        self.layers.append(nn.Linear(layer_dims[-2], layer_dims[-1]))\n",
    "        self.layers.append(nn.Sigmoid())\n",
    "\n",
    "    def forward(self, x):\n",
    "        for layer in self.layers:\n",
    "            x = layer(x.to(torch.float32))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LLayerNN(\n",
       "  (layers): ModuleList(\n",
       "    (0): Linear(in_features=12288, out_features=10000, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=10000, out_features=3000, bias=True)\n",
       "    (3): ReLU()\n",
       "    (4): Linear(in_features=3000, out_features=1000, bias=True)\n",
       "    (5): ReLU()\n",
       "    (6): Linear(in_features=1000, out_features=500, bias=True)\n",
       "    (7): ReLU()\n",
       "    (8): Linear(in_features=500, out_features=100, bias=True)\n",
       "    (9): ReLU()\n",
       "    (10): Linear(in_features=100, out_features=50, bias=True)\n",
       "    (11): ReLU()\n",
       "    (12): Linear(in_features=50, out_features=20, bias=True)\n",
       "    (13): ReLU()\n",
       "    (14): Linear(in_features=20, out_features=7, bias=True)\n",
       "    (15): ReLU()\n",
       "    (16): Linear(in_features=7, out_features=5, bias=True)\n",
       "    (17): ReLU()\n",
       "    (18): Linear(in_features=5, out_features=1, bias=True)\n",
       "    (19): Sigmoid()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 274,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer_dims = [12288, 10000, 3000, 1000, 500, 100, 50, 20, 7, 5, 1]\n",
    "\n",
    "model = LLayerNN(layer_dims)\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Compare test accuracy using different optimizers: SGD, Adam, Momentum."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_x, train_y, test_x, test_y, num_epochs=100, optimizer = torch.optim.SGD(model.parameters(), lr=0.001, momentum=0), criterion=nn.CrossEntropyLoss()):\n",
    "    loss_hist_train = [0] * num_epochs\n",
    "    accuracy_hist_train = [0] * num_epochs\n",
    "    loss_hist_valid = [0] * num_epochs\n",
    "    accuracy_hist_valid = [0] * num_epochs\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        X = torch.tensor(train_x.T, dtype=torch.float32)\n",
    "        Y = torch.tensor(train_y, dtype=torch.float32)\n",
    "        model.train()\n",
    "        outputs = model(X)\n",
    "        \n",
    "        loss = criterion(outputs.T.to(torch.float32), Y)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        loss_hist_train[epoch] += loss.item()\n",
    "        is_correct = (torch.argmax(outputs, dim=1) == torch.tensor(train_y, dtype=torch.float32)).float()\n",
    "        accuracy_hist_train[epoch] += is_correct.sum().cpu()\n",
    "        \n",
    "        loss_hist_train[epoch] /= len(train_dl.dataset)\n",
    "        accuracy_hist_train[epoch] /= len(train_dl.dataset)\n",
    "        \n",
    "        model.eval()\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            \n",
    "            X_test = torch.tensor(test_x.T, dtype=torch.float32)\n",
    "            Y_test = torch.tensor(test_y, dtype=torch.float32)\n",
    "            \n",
    "            pred_test = model(X_test)\n",
    "            loss = criterion(pred_test.T.to(torch.float32), Y_test)\n",
    "            loss_hist_valid[epoch] += loss.item() \n",
    "            is_correct = (torch.argmax(pred_test, dim=1) == Y_test).float() \n",
    "            accuracy_hist_valid[epoch] += is_correct.sum().cpu()\n",
    "\n",
    "        loss_hist_valid[epoch] /= len(valid_dl.dataset)\n",
    "        accuracy_hist_valid[epoch] /= len(valid_dl.dataset)\n",
    "        \n",
    "        print(f'Epoch {epoch+1} accuracy: {accuracy_hist_train[epoch]:.4f} val_accuracy: {accuracy_hist_valid[epoch]:.4f}')\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 accuracy: 0.0027 val_accuracy: 0.0017\n",
      "Epoch 2 accuracy: 0.0027 val_accuracy: 0.0017\n",
      "Epoch 3 accuracy: 0.0027 val_accuracy: 0.0017\n",
      "Epoch 4 accuracy: 0.0027 val_accuracy: 0.0017\n",
      "Epoch 5 accuracy: 0.0027 val_accuracy: 0.0017\n",
      "Epoch 6 accuracy: 0.0027 val_accuracy: 0.0017\n",
      "Epoch 7 accuracy: 0.0027 val_accuracy: 0.0017\n",
      "Epoch 8 accuracy: 0.0027 val_accuracy: 0.0017\n",
      "Epoch 9 accuracy: 0.0027 val_accuracy: 0.0017\n",
      "Epoch 10 accuracy: 0.0027 val_accuracy: 0.0017\n",
      "Epoch 11 accuracy: 0.0027 val_accuracy: 0.0017\n",
      "Epoch 12 accuracy: 0.0027 val_accuracy: 0.0017\n",
      "Epoch 13 accuracy: 0.0027 val_accuracy: 0.0017\n",
      "Epoch 14 accuracy: 0.0027 val_accuracy: 0.0017\n",
      "Epoch 15 accuracy: 0.0027 val_accuracy: 0.0017\n",
      "Epoch 16 accuracy: 0.0027 val_accuracy: 0.0017\n",
      "Epoch 17 accuracy: 0.0027 val_accuracy: 0.0017\n",
      "Epoch 18 accuracy: 0.0027 val_accuracy: 0.0017\n",
      "Epoch 19 accuracy: 0.0027 val_accuracy: 0.0017\n",
      "Epoch 20 accuracy: 0.0027 val_accuracy: 0.0017\n",
      "Epoch 21 accuracy: 0.0027 val_accuracy: 0.0017\n",
      "Epoch 22 accuracy: 0.0027 val_accuracy: 0.0017\n",
      "Epoch 23 accuracy: 0.0027 val_accuracy: 0.0017\n",
      "Epoch 24 accuracy: 0.0027 val_accuracy: 0.0017\n",
      "Epoch 25 accuracy: 0.0027 val_accuracy: 0.0017\n",
      "Epoch 26 accuracy: 0.0027 val_accuracy: 0.0017\n",
      "Epoch 27 accuracy: 0.0027 val_accuracy: 0.0017\n",
      "Epoch 28 accuracy: 0.0027 val_accuracy: 0.0017\n",
      "Epoch 29 accuracy: 0.0027 val_accuracy: 0.0017\n",
      "Epoch 30 accuracy: 0.0027 val_accuracy: 0.0017\n",
      "Epoch 31 accuracy: 0.0027 val_accuracy: 0.0017\n",
      "Epoch 32 accuracy: 0.0027 val_accuracy: 0.0017\n",
      "Epoch 33 accuracy: 0.0027 val_accuracy: 0.0017\n",
      "Epoch 34 accuracy: 0.0027 val_accuracy: 0.0017\n",
      "Epoch 35 accuracy: 0.0027 val_accuracy: 0.0017\n",
      "Epoch 36 accuracy: 0.0027 val_accuracy: 0.0017\n",
      "Epoch 37 accuracy: 0.0027 val_accuracy: 0.0017\n",
      "Epoch 38 accuracy: 0.0027 val_accuracy: 0.0017\n",
      "Epoch 39 accuracy: 0.0027 val_accuracy: 0.0017\n",
      "Epoch 40 accuracy: 0.0027 val_accuracy: 0.0017\n",
      "Epoch 41 accuracy: 0.0027 val_accuracy: 0.0017\n",
      "Epoch 42 accuracy: 0.0027 val_accuracy: 0.0017\n",
      "Epoch 43 accuracy: 0.0027 val_accuracy: 0.0017\n",
      "Epoch 44 accuracy: 0.0027 val_accuracy: 0.0017\n",
      "Epoch 45 accuracy: 0.0027 val_accuracy: 0.0017\n",
      "Epoch 46 accuracy: 0.0027 val_accuracy: 0.0017\n",
      "Epoch 47 accuracy: 0.0027 val_accuracy: 0.0017\n",
      "Epoch 48 accuracy: 0.0027 val_accuracy: 0.0017\n",
      "Epoch 49 accuracy: 0.0027 val_accuracy: 0.0017\n",
      "Epoch 50 accuracy: 0.0027 val_accuracy: 0.0017\n",
      "Epoch 51 accuracy: 0.0027 val_accuracy: 0.0017\n",
      "Epoch 52 accuracy: 0.0027 val_accuracy: 0.0017\n",
      "Epoch 53 accuracy: 0.0027 val_accuracy: 0.0017\n",
      "Epoch 54 accuracy: 0.0027 val_accuracy: 0.0017\n",
      "Epoch 55 accuracy: 0.0027 val_accuracy: 0.0017\n",
      "Epoch 56 accuracy: 0.0027 val_accuracy: 0.0017\n",
      "Epoch 57 accuracy: 0.0027 val_accuracy: 0.0017\n",
      "Epoch 58 accuracy: 0.0027 val_accuracy: 0.0017\n",
      "Epoch 59 accuracy: 0.0027 val_accuracy: 0.0017\n",
      "Epoch 60 accuracy: 0.0027 val_accuracy: 0.0017\n",
      "Epoch 61 accuracy: 0.0027 val_accuracy: 0.0017\n",
      "Epoch 62 accuracy: 0.0027 val_accuracy: 0.0017\n",
      "Epoch 63 accuracy: 0.0027 val_accuracy: 0.0017\n",
      "Epoch 64 accuracy: 0.0027 val_accuracy: 0.0017\n",
      "Epoch 65 accuracy: 0.0027 val_accuracy: 0.0017\n",
      "Epoch 66 accuracy: 0.0027 val_accuracy: 0.0017\n",
      "Epoch 67 accuracy: 0.0027 val_accuracy: 0.0017\n",
      "Epoch 68 accuracy: 0.0027 val_accuracy: 0.0017\n",
      "Epoch 69 accuracy: 0.0027 val_accuracy: 0.0017\n",
      "Epoch 70 accuracy: 0.0027 val_accuracy: 0.0017\n",
      "Epoch 71 accuracy: 0.0027 val_accuracy: 0.0017\n",
      "Epoch 72 accuracy: 0.0027 val_accuracy: 0.0017\n",
      "Epoch 73 accuracy: 0.0027 val_accuracy: 0.0017\n",
      "Epoch 74 accuracy: 0.0027 val_accuracy: 0.0017\n",
      "Epoch 75 accuracy: 0.0027 val_accuracy: 0.0017\n",
      "Epoch 76 accuracy: 0.0027 val_accuracy: 0.0017\n",
      "Epoch 77 accuracy: 0.0027 val_accuracy: 0.0017\n",
      "Epoch 78 accuracy: 0.0027 val_accuracy: 0.0017\n",
      "Epoch 79 accuracy: 0.0027 val_accuracy: 0.0017\n",
      "Epoch 80 accuracy: 0.0027 val_accuracy: 0.0017\n",
      "Epoch 81 accuracy: 0.0027 val_accuracy: 0.0017\n",
      "Epoch 82 accuracy: 0.0027 val_accuracy: 0.0017\n",
      "Epoch 83 accuracy: 0.0027 val_accuracy: 0.0017\n",
      "Epoch 84 accuracy: 0.0027 val_accuracy: 0.0017\n",
      "Epoch 85 accuracy: 0.0027 val_accuracy: 0.0017\n",
      "Epoch 86 accuracy: 0.0027 val_accuracy: 0.0017\n",
      "Epoch 87 accuracy: 0.0027 val_accuracy: 0.0017\n",
      "Epoch 88 accuracy: 0.0027 val_accuracy: 0.0017\n",
      "Epoch 89 accuracy: 0.0027 val_accuracy: 0.0017\n",
      "Epoch 90 accuracy: 0.0027 val_accuracy: 0.0017\n",
      "Epoch 91 accuracy: 0.0027 val_accuracy: 0.0017\n",
      "Epoch 92 accuracy: 0.0027 val_accuracy: 0.0017\n",
      "Epoch 93 accuracy: 0.0027 val_accuracy: 0.0017\n",
      "Epoch 94 accuracy: 0.0027 val_accuracy: 0.0017\n",
      "Epoch 95 accuracy: 0.0027 val_accuracy: 0.0017\n",
      "Epoch 96 accuracy: 0.0027 val_accuracy: 0.0017\n",
      "Epoch 97 accuracy: 0.0027 val_accuracy: 0.0017\n",
      "Epoch 98 accuracy: 0.0027 val_accuracy: 0.0017\n",
      "Epoch 99 accuracy: 0.0027 val_accuracy: 0.0017\n",
      "Epoch 100 accuracy: 0.0027 val_accuracy: 0.0017\n"
     ]
    }
   ],
   "source": [
    "train(model, train_x, train_y, test_x, test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 accuracy: 0.0027 val_accuracy: 0.0017\n",
      "Epoch 2 accuracy: 0.0027 val_accuracy: 0.0017\n",
      "Epoch 3 accuracy: 0.0027 val_accuracy: 0.0017\n",
      "Epoch 4 accuracy: 0.0027 val_accuracy: 0.0017\n",
      "Epoch 5 accuracy: 0.0027 val_accuracy: 0.0017\n",
      "Epoch 6 accuracy: 0.0027 val_accuracy: 0.0017\n",
      "Epoch 7 accuracy: 0.0027 val_accuracy: 0.0017\n",
      "Epoch 8 accuracy: 0.0027 val_accuracy: 0.0017\n",
      "Epoch 9 accuracy: 0.0027 val_accuracy: 0.0017\n",
      "Epoch 10 accuracy: 0.0027 val_accuracy: 0.0017\n"
     ]
    }
   ],
   "source": [
    "train(model, train_x, train_y, test_x, test_y, optimizer = torch.optim.Adam(model.parameters(), lr=0.0001), num_epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Momentum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 accuracy: 0.0027 val_accuracy: 0.0017\n",
      "Epoch 2 accuracy: 0.0027 val_accuracy: 0.0017\n",
      "Epoch 3 accuracy: 0.0027 val_accuracy: 0.0017\n",
      "Epoch 4 accuracy: 0.0027 val_accuracy: 0.0017\n",
      "Epoch 5 accuracy: 0.0027 val_accuracy: 0.0017\n",
      "Epoch 6 accuracy: 0.0027 val_accuracy: 0.0017\n",
      "Epoch 7 accuracy: 0.0027 val_accuracy: 0.0017\n",
      "Epoch 8 accuracy: 0.0027 val_accuracy: 0.0017\n",
      "Epoch 9 accuracy: 0.0027 val_accuracy: 0.0017\n",
      "Epoch 10 accuracy: 0.0027 val_accuracy: 0.0017\n"
     ]
    }
   ],
   "source": [
    "train(model, train_x, train_y, test_x, test_y, optimizer = torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.9), num_epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
